# MMA Project â€“ Evaluador AutomÃ¡tico de Respuestas AcadÃ©micas

Este proyecto es una aplicaciÃ³n web diseÃ±ada para ayudar a profesores a evaluar automÃ¡ticamente respuestas de estudiantes usando modelos de lenguaje de Fireworks.ai.

## âœ¨ CaracterÃ­sticas

- GestiÃ³n de problemas acadÃ©micos con metadatos (tema, tipo, criterio, crÃ©ditosâ€¦).
- EvaluaciÃ³n automÃ¡tica de respuestas usando LLMs vÃ­a Fireworks.ai.
- Interfaz moderna con filtros, modo oscuro, y paginaciÃ³n.
- Arquitectura desacoplada: Frontend (Next.js) + Backend (Flask).

---

## ğŸ§  TecnologÃ­as

### ğŸ–¥ï¸ Frontend
- [Next.js](https://nextjs.org/)
- TypeScript
- TailwindCSS

### ğŸ§ª Backend
- [Flask](https://flask.palletsprojects.com/)
- Flask-SQLAlchemy
- Flask-Migrate
- Fireworks API
- Python 3.12+

---

## âš™ï¸ InstalaciÃ³n

### 1. Clona el repositorio

```bash
git clone https://github.com/tu-usuario/MMA_Project.git
cd MMA_Project/backend
```

### 2. Configura el Backend

```bash
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt
```

Configura las variables de entorno en un archivo .env:

```bash
FIREWORKS_API_KEY=sk-tu-api-key
```

Ejecuta la app:

```bash
python run.py
```

La API se levantarÃ¡ en http://localhost:5000.

### 3. Configura el Frontend

```bash
cd ../frontend
npm install
npm run dev
```

La app estarÃ¡ disponible en http://localhost:3000.

    AsegÃºrate de que el backend estÃ¡ corriendo en el puerto 5000 para que las peticiones funcionen correctamente.

## ğŸ” Estructura del proyecto

```bash
MMA_Project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”œâ”€â”€ run.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx
â”‚   â”‚   â””â”€â”€ problems/
â”‚   â”‚       â”œâ”€â”€ [id]/page.tsx
â”‚   â”‚       â””â”€â”€ create/page.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ ProblemFilters.tsx
â”‚   â””â”€â”€ tailwind.config.ts
â””â”€â”€ README.md

```

## ğŸ§ª EvaluaciÃ³n con Fireworks.ai

La app se comunica con modelos LLM usando la API de Fireworks:

* El backend prepara un prompt detallado con:

  * Tema

   * Tipo de pregunta

   * SoluciÃ³n esperada

   * Respuesta del estudiante

   * Criterio de evaluaciÃ³n

* El modelo devuelve un razonamiento y una puntuaciÃ³n.

**Puedes ver o modificar el prompt en:**
`backend/app/llm/prompts.py`

## ğŸ“¥ Poblado de la base de datos (opcional)

Puedes usar un script seed.py en el backend para poblar la base de datos con ejemplos. AsegÃºrate de que estÃ© dentro del contexto de aplicaciÃ³n.

## âœï¸ Contribuciones

Â¡Se aceptan contribuciones! Puedes:

* Agregar tipos de problemas nuevos

* Implementar soporte para mÃºltiples LLMs

* Mejorar el sistema de feedback visual

* Agregar exportaciÃ³n de resultados o historial

## ğŸ§‘â€ğŸ’» Autor

DarÃ­o LÃ³pez FalcÃ³nâ€” estudiante de Ciencias de la ComputaciÃ³n de la Universidad de La Habana

## ğŸ“„ Licencia

MIT License.